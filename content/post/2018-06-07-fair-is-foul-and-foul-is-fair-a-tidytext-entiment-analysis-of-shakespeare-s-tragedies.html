---
title: "Fair is foul, and foul is fair: a tidytext sentiment analysis of Shakespeare’s tragedies"
summary: "Part 1 of my exploration of the tidytext R package for various text mining tasks"
author: "Peer Christensen"
date: '2018-06-07'
slug: fair-is-foul-and-foul-is-fair-a-tidytext-entiment-analysis-of-shakespeare-s-tragedies
categories:
  - R
  - Text mining
tags:
  - Sentiment analysis
  - Tidytext
  - gutenbergr
header:
  caption: ''
  image: ''
---



<p>
Sentiment analysis can be used for many purposes and applied to all kinds of texts. In this exploratory analysis, we’ll use a tidytext approach to examine the use of sentiment words in the tragedies written by William Shakespeare. I’ve previously used Python for scraping and mining texts. However, I recently stumbled upon the tidytext R package by Julia Silge and David Robinson as well as their excellent <a href="https://www.tidytextmining.com/">book</a> and ressource on combining tidytext with other tidy tools in R. This approach has made my life so much easier!
<p>
<div id="loading-packages" class="section level3">
<h3>Loading packages</h3>
<pre class="r"><code>if(!require(&quot;pacman&quot;)) install.packages(&quot;pacman&quot;)
pacman::p_load(tidyverse,tidytext,jtools,gridExtra,zoo,data.table,gutenbergr)</code></pre>
<p>
</div>
<div id="customizing-a-ggplot2-theme" class="section level3">
<h3>Customizing a ggplot2 theme</h3>
Because we’ll create several ggplots to visualize sentiments in Shakespeare’s tragedies, it’ll be worth storing some plotting options in a customized theme. Rather than starting from scratch, we’ll use the APA theme from the jtools package and override some of the theme settings.
<p>
<pre class="r"><code>my_theme &lt;- function() {
  theme_apa(legend.pos = &quot;none&quot;) +
    theme(panel.background = element_blank(),
          plot.background = element_rect(fill = &quot;antiquewhite1&quot;),
          panel.border = element_blank(),                     # facet border
          strip.background = element_blank(),                 # facet title background
          plot.margin = unit(c(.5, .5, .5, .5), &quot;cm&quot;)) 
}</code></pre>
<p>
</div>
<div id="loading-our-data" class="section level3">
<h3>Loading our data</h3>
Initially when I started working on Shakespeare’s plays, I downloaded the texts as .txt files and cleaned them in several steps. At the bottom of this page, I provide some code showing how I did it.
<p>
A more efficient way to gather public domain literary texts, such as Shakespeare’s plays, is to use David Robinson’s gutenbergr package. Let’s first see what’s available by Shakespeare.
<p>
<pre class="r"><code>shakespeare &lt;- gutenberg_works(author == &quot;Shakespeare, William&quot;) 

shakespeare</code></pre>
<pre><code>## # A tibble: 79 x 8
##    gutenberg_id title author gutenberg_autho… language gutenberg_books…
##           &lt;int&gt; &lt;chr&gt; &lt;chr&gt;             &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;           
##  1         1041 Shak… Shake…               65 en       &lt;NA&gt;            
##  2         1045 Venu… Shake…               65 en       &lt;NA&gt;            
##  3         1500 King… Shake…               65 en       &lt;NA&gt;            
##  4         1501 Hist… Shake…               65 en       &lt;NA&gt;            
##  5         1502 The … Shake…               65 en       &lt;NA&gt;            
##  6         1503 The … Shake…               65 en       &lt;NA&gt;            
##  7         1504 The … Shake…               65 en       &lt;NA&gt;            
##  8         1505 The … Shake…               65 en       &lt;NA&gt;            
##  9         1507 The … Shake…               65 en       &lt;NA&gt;            
## 10         1508 The … Shake…               65 en       &lt;NA&gt;            
## # ... with 69 more rows, and 2 more variables: rights &lt;chr&gt;,
## #   has_text &lt;lgl&gt;</code></pre>
<p>
We then collect the IDs for the plays that we want and check that they match before we download the texts.
<p>
<pre class="r"><code>IDs = shakespeare[c(15,23,33,34,53,54,55,56,57,58),]$gutenberg_id

shakespeare %&gt;% 
  filter(gutenberg_id %in% IDs)</code></pre>
<pre><code>## # A tibble: 10 x 8
##    gutenberg_id title author gutenberg_autho… language gutenberg_books…
##           &lt;int&gt; &lt;chr&gt; &lt;chr&gt;             &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;           
##  1         1513 Rome… Shake…               65 en       &lt;NA&gt;            
##  2         1522 Juli… Shake…               65 en       &lt;NA&gt;            
##  3         1533 Macb… Shake…               65 en       Opera           
##  4         1534 Anto… Shake…               65 en       &lt;NA&gt;            
##  5         2259 Cori… Shake…               65 en       &lt;NA&gt;            
##  6         2260 Titu… Shake…               65 en       &lt;NA&gt;            
##  7         2262 Timo… Shake…               65 en       &lt;NA&gt;            
##  8         2265 Haml… Shake…               65 en       Best Books Ever…
##  9         2266 King… Shake…               65 en       Banned Books fr…
## 10         2267 Othe… Shake…               65 en       &lt;NA&gt;            
## # ... with 2 more variables: rights &lt;chr&gt;, has_text &lt;lgl&gt;</code></pre>
<p>
It looks like we have the right texts. Let’s download the texts, store them in a tibble and look at the data.
<p>
<pre class="r"><code>plays = gutenberg_download(IDs,meta_fields = &quot;title&quot;)

plays</code></pre>
<pre><code>## # A tibble: 46,795 x 3
##    gutenberg_id text                       title           
##           &lt;int&gt; &lt;chr&gt;                      &lt;chr&gt;           
##  1         1513 ROMEO AND JULIET           Romeo and Juliet
##  2         1513 &quot;&quot;                         Romeo and Juliet
##  3         1513 by William Shakespeare     Romeo and Juliet
##  4         1513 &quot;&quot;                         Romeo and Juliet
##  5         1513 &quot;&quot;                         Romeo and Juliet
##  6         1513 &quot;&quot;                         Romeo and Juliet
##  7         1513 &quot;&quot;                         Romeo and Juliet
##  8         1513 PERSONS REPRESENTED        Romeo and Juliet
##  9         1513 &quot;&quot;                         Romeo and Juliet
## 10         1513 Escalus, Prince of Verona. Romeo and Juliet
## # ... with 46,785 more rows</code></pre>
<p>
</div>
<div id="creating-a-data-frame-of-sentiment-words" class="section level3">
<h3>Creating a data frame of sentiment words</h3>
<p>
<p>We see that the text variable contains one line of text for each row. Given this format, we can create a new data frame with a row for each word token found in the Bing lexicon of sentiment words. By using this lexicon, sentiment words are simpky assigned a value of positive or negative. Have a look at the other options with ?get_sentiments. We will try using the nrc lexicon later on.</p>
<pre class="r"><code>sentiments = plays            %&gt;% 
  group_by(title)             %&gt;%
  mutate(line = row_number()) %&gt;%      # we will use line numbers later
  unnest_tokens(word, text)   %&gt;%      # tokenize words
  #anti_join(stop_words) %&gt;%           # in case we would like to remove stop words
  inner_join(get_sentiments(&quot;bing&quot;))   # keep only words found in the Bing lexicon

sentiments</code></pre>
<pre><code>## # A tibble: 16,562 x 5
## # Groups:   title [?]
##    gutenberg_id title             line word       sentiment
##           &lt;int&gt; &lt;chr&gt;            &lt;int&gt; &lt;chr&gt;      &lt;chr&gt;    
##  1         1513 Romeo and Juliet    50 dignity    positive 
##  2         1513 Romeo and Juliet    51 fair       positive 
##  3         1513 Romeo and Juliet    52 grudge     negative 
##  4         1513 Romeo and Juliet    52 break      negative 
##  5         1513 Romeo and Juliet    53 unclean    negative 
##  6         1513 Romeo and Juliet    54 fatal      negative 
##  7         1513 Romeo and Juliet    56 overthrows negative 
##  8         1513 Romeo and Juliet    57 death      negative 
##  9         1513 Romeo and Juliet    57 strife     negative 
## 10         1513 Romeo and Juliet    58 fearful    negative 
## # ... with 16,552 more rows</code></pre>
<p>
We could also further subset our data frame by omitting so-called “stop words” defined in the stop_words variable. However, this is perhaps not ideal when we examine the following output showing which stop words match words in our data. Note that our choice here is important and will likely affect the analysis. In particular, it is clear that most of the words in question have a positive valence in the lexicon.
<p>
<pre class="r"><code>table(sentiments$word[sentiments$word %in% stop_words$word])</code></pre>
<pre><code>## 
## available      best    better     clear    enough      good     great 
##        12       159       151         7        87       762       264 
##  greatest important      like     right  sensible     sorry     thank 
##        15         1       503        81         6        26        21 
##    useful   welcome      well   willing    wonder      work 
##         1       121       606         9        28        25</code></pre>
<p>
With that in mind, we can now plot the number of positive and negative words in each play.
<p>
<pre class="r"><code>sentiments         %&gt;% 
  count(sentiment) %&gt;%
  ggplot(aes(x = sentiment, y = n, fill = title)) + 
  geom_bar(stat = &quot;identity&quot;) +
  facet_wrap(~title) +
  scale_fill_viridis_d(option = &quot;B&quot;) +
  my_theme()</code></pre>
<img src="/post/2018-06-07-fair-is-foul-and-foul-is-fair-a-tidytext-entiment-analysis-of-shakespeare-s-tragedies_files/figure-html/unnamed-chunk-8-1.png" width="960" />
<p>
For the figure below, we’ll use the nrc lexicon, which associates words with basic emotions.
<p>
<pre class="r"><code>plays                               %&gt;% 
  group_by(title)                   %&gt;%
  mutate(line = row_number())       %&gt;%
  unnest_tokens(word, text)         %&gt;%
  #anti_join(stop_words)            %&gt;%
  inner_join(get_sentiments(&quot;nrc&quot;)) %&gt;% 
  count(sentiment) %&gt;%
  ggplot(aes(x = sentiment, y = n, fill = sentiment)) + 
  geom_bar(stat = &quot;identity&quot;) +
  facet_wrap(~title) +
  scale_fill_viridis_d(option = &quot;B&quot;) +
  my_theme() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) </code></pre>
<img src="/post/2018-06-07-fair-is-foul-and-foul-is-fair-a-tidytext-entiment-analysis-of-shakespeare-s-tragedies_files/figure-html/unnamed-chunk-9-1.png" width="960" />
<p>
Using our first data frame created with the Bing lexicon, let’s now rank the plays according to their ratio of negative words.
<p>
<pre class="r"><code>sentiments                       %&gt;% 
  count(sentiment)               %&gt;%
  spread(sentiment, n, fill = 0) %&gt;%
  mutate(ratio = negative / (negative + positive)) %&gt;%
  ungroup()                      %&gt;%
  ggplot(aes(x = reorder(title, ratio), y = ratio, fill = ratio)) + 
  geom_bar(stat = &quot;identity&quot;) +
  scale_fill_viridis_c(option = &quot;B&quot;, direction = -1) +
  my_theme() + 
  labs(title = &quot;Plays ranked by ratio of negative sentiment words&quot;,
       y     = &quot;ratio negative words&quot;,
       x     = &quot;plays&quot;) +
  coord_flip()</code></pre>
<img src="/post/2018-06-07-fair-is-foul-and-foul-is-fair-a-tidytext-entiment-analysis-of-shakespeare-s-tragedies_files/figure-html/unnamed-chunk-10-1.png" width="960" />
<p>
</div>
<div id="sentiments-over-time" class="section level3">
<h3>Sentiments over time</h3>
<p>It might also be interesting to examine the ebb and flow of sentiments as each play unfolds. To do so, we can use integer division and find the number of positive and negative words for each chunk of text. Here, we’ll use chunks with 100 words in each and subtract the number of negative from positive words.</p>
<pre class="r"><code>sentiments %&gt;%
  # count number of positive and negative words for each chunk of 100 lines
  count(title, index = line %/% 100, sentiment) %&gt;%  
  spread(sentiment, n, fill = 0)                %&gt;%                 
  mutate(sentiment = positive - negative)       %&gt;%
  ggplot(aes(index, sentiment, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~title,scales = &quot;free_x&quot;) +
  scale_fill_viridis_c(option = &quot;B&quot;) +
  my_theme()</code></pre>
<img src="/post/2018-06-07-fair-is-foul-and-foul-is-fair-a-tidytext-entiment-analysis-of-shakespeare-s-tragedies_files/figure-html/unnamed-chunk-11-1.png" width="1152" />
<p>
It might also be useful to further examine the “trend”&quot; by adding a line indicating the rolling mean sentiment score. As an example, let’s try this with Romeo and Juliet using a lag of 5 indices.
<p>
<pre class="r"><code>sentiments %&gt;%
  filter(title == &quot;Romeo and Juliet&quot;)           %&gt;%
  count(title, index = line %/% 100, sentiment) %&gt;%
  spread(sentiment, n, fill = 0)                %&gt;%
  mutate(sentiment = positive - negative)       %&gt;%
  mutate(rollMean = rollmean(sentiment, 5, fill = NA)) %&gt;%             # zoo package
  ggplot(aes(index, sentiment, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  geom_line(aes(x = index, y = rollMean),size = 4, colour = &quot;antiquewhite1&quot;) +
  geom_line(aes(x = index, y = rollMean), size = 1) +
  scale_fill_viridis_c(option = &quot;B&quot;) +
  labs(title = &quot;Romeo and Juliet&quot;) +
  my_theme()</code></pre>
<img src="/post/2018-06-07-fair-is-foul-and-foul-is-fair-a-tidytext-entiment-analysis-of-shakespeare-s-tragedies_files/figure-html/unnamed-chunk-12-1.png" width="960" />
<p>
Though it requires a bit more work, it might be worthwhile to indicate where the individual acts begin. First, we will create a data frame containing the lines in which individual acts begin. We find the relevant lines with regular expressions in line 4 of the below code looking for the word “act” (or, in some cases, “actus”). For each hit, we assign a number
<p>
<pre class="r"><code>acts = plays                                  %&gt;% 
  filter(title == &quot;Romeo and Juliet&quot;)         %&gt;%
  mutate(line = row_number())                 %&gt;%
  mutate(act = cumsum(str_detect(text, regex(&quot;^act |^actus &quot;, ignore_case = T)))) %&gt;% 
  ungroup()                                   %&gt;%
  unnest_tokens(word, text)                   %&gt;%
  #anti_join(stop_words) %&gt;%
  inner_join(get_sentiments(&quot;bing&quot;))          %&gt;%
  count(act, index = line %/% 100, sentiment) %&gt;%
  mutate(new_act = act != shift(act,1))       %&gt;%   # add a logical vector indicating where acts begin
  spread(sentiment, n, fill = 0)              %&gt;%
  mutate(sentiment = positive - negative)     %&gt;%
  filter(new_act == T, act &gt; 0)               %&gt;%   # keep only indices where acts begin, remove indices before act 1
  select(index,act)

acts</code></pre>
<pre><code>## # A tibble: 5 x 2
##   index   act
##   &lt;dbl&gt; &lt;int&gt;
## 1     0     1
## 2    13     2
## 3    25     3
## 4    38     4
## 5    45     5</code></pre>
<p>
We’ll also create a new data frame with the functions we used to prepare the data for the previous plot.
<p>
<pre class="r"><code>sentiments2 = plays                       %&gt;% 
  filter(title == &quot;Romeo and Juliet&quot;)     %&gt;%
  mutate(line = row_number())             %&gt;%
  ungroup()                               %&gt;%
  unnest_tokens(word, text)               %&gt;%
  #anti_join(stop_words)                  %&gt;%
  inner_join(get_sentiments(&quot;bing&quot;))      %&gt;%
  count(index = line %/% 100, sentiment)  %&gt;%
  spread(sentiment, n, fill = 0)          %&gt;%
  mutate(sentiment = positive - negative)</code></pre>
<p>
Let’s then plot the same data only with lines and text indicating the beginning of each act.
<p>
<pre class="r"><code>sentiments2 %&gt;% 
  ggplot(aes(index, sentiment, fill = sentiment)) +
  geom_vline(data = acts[-1,],
             aes(xintercept = index - 0.5),linetype = &quot;dashed&quot;) +
  geom_col(show.legend = FALSE,position = &quot;dodge&quot;) +
  scale_fill_viridis_c(option = &quot;B&quot;) + 
  labs(title = &quot;Romeo and Juliet&quot;) +
  annotate(&quot;text&quot;, x = acts$index + 2, y = 22, label = paste0(&quot;act &quot;, acts$act), size = 5) +
  my_theme()</code></pre>
<img src="/post/2018-06-07-fair-is-foul-and-foul-is-fair-a-tidytext-entiment-analysis-of-shakespeare-s-tragedies_files/figure-html/unnamed-chunk-15-1.png" width="960" />
<p>
</div>
<div id="finding-the-most-common-sentiment-words" class="section level3">
<h3>Finding the most common sentiment words</h3>
Focusing now on the words themselves, we can easily get an overview of the most common positive and negative words. In this case, we select the ten most common words for each category.
<p>
<pre class="r"><code>word_counts &lt;- sentiments %&gt;%
  ungroup()               %&gt;%
  count(word, sentiment, sort = TRUE) %&gt;%
  group_by(sentiment)     %&gt;%
  top_n(10)               %&gt;%
  ungroup()               %&gt;%
  arrange(sentiment, -n)  %&gt;%
  mutate(order = rev(row_number()))       # we need the order variable to ensure proper ranking of words</code></pre>
<p>
Recall that we chose to keep the sentiment words that matched stop words. In the plot below, we clearly see the consequence of our choice. The top four spots among positive words are populated by stop words.
<p>
<pre class="r"><code>word_counts %&gt;%
  ggplot(aes(order, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  scale_x_continuous(
    breaks = word_counts$order,
    labels = word_counts$word,
    expand = c(0,0)) +
  facet_wrap(~sentiment, scales = &quot;free_y&quot;) +
  labs(y = &quot;Contribution to sentiment&quot;, x = NULL) +
  coord_flip() +
  scale_fill_viridis_d(option = &quot;B&quot;, begin = .2, end = .8) +
  my_theme()</code></pre>
<img src="/post/2018-06-07-fair-is-foul-and-foul-is-fair-a-tidytext-entiment-analysis-of-shakespeare-s-tragedies_files/figure-html/unnamed-chunk-17-1.png" width="960" />
<p>
Let’s do the same for each play and store individual plots in a list using a for loop. Note that if there are ties for tenth place, all tied words are plotted.
<p>
<pre class="r"><code>titles = unique(sentiments$title)
plots = list()
for (i in titles){
  word_counts = sentiments %&gt;%
    filter(title == i)     %&gt;%
    count(word, sentiment, sort = TRUE) %&gt;%
    ungroup()              %&gt;%
    group_by(sentiment)    %&gt;%
    top_n(10)              %&gt;%
    ungroup()              %&gt;%
    arrange(sentiment, -n) %&gt;%
    mutate(order = rev(row_number()))
  
  plots[[i]] = word_counts %&gt;%
    ggplot(aes(order, n, fill = sentiment)) +
    geom_col(show.legend = FALSE) +
    scale_x_continuous(
      breaks = word_counts$order,
      labels = word_counts$word,
      expand = c(0,0)) +
    facet_wrap(~sentiment, scales = &quot;free_y&quot;) +
    labs(y = &quot;Contribution to sentiment&quot;,x = NULL) +
    ggtitle(i) +
    coord_flip() +
    scale_fill_viridis_d(option = &quot;B&quot;,begin = .2,end = .8) +
    my_theme()
  
    #print(plots[[i]])              # in case we want to create individual plots                 
}</code></pre>
<p>
Let’s create a grid and plot the first nine plays.
<p>
<pre class="r"><code>grid.arrange(grobs = plots[1:9], ncol = 3)</code></pre>
<img src="/post/2018-06-07-fair-is-foul-and-foul-is-fair-a-tidytext-entiment-analysis-of-shakespeare-s-tragedies_files/figure-html/unnamed-chunk-19-1.png" width="1152" />
<p>
</div>
<div id="conclusion" class="section level3">
<h3>Conclusion</h3>
The aim of this analysis was simply to illustrate the ease with which one can quantify and explore texts with the tidytext package in combination with other tidy tools. In future posts, I will apply other text mining methods (e.g. word frequency, n-gram analysis and topic modeling) to Shakespeare’s tragedies.
<p>
</div>
<div id="preparing-data-from-.txt-files" class="section level3">
<h3>Preparing data from .txt files</h3>
<p>I started out with a .txt file containing the text for each play before using gutenbergr to grab the text. Of course, we may want to use the same text mining methods on many other kinds of texts not in the Gutenberg Project catalogue. The following code shows how one can take a collection of .txt files to produce a data frame structured in the same way as before.</p>
<pre class="r"><code>##### manual cleaning
playList = list.files(pattern = &quot;txt&quot;)        # create a list of documents

df = tibble()
for (play in playList){
  
  text = glue(read_file(play))
  text = str_trim(gsub(&quot;[A-Z]{2,}&quot;,&quot;&quot;,text))  # remove uppercase words
  text = tolower(text)                        # all words to lowercase
  #text = removeWords(text,stopwords(&quot;en&quot;))   # remove stop words
  tokens = data_frame(text = text) %&gt;%        # tokenize words
    unnest_tokens(word, text)
  
  sentiments = tokens                  %&gt;%
    inner_join(get_sentiments(&quot;bing&quot;)) %&gt;%
    count(sentiment)                   %&gt;%
    spread(sentiment, n, fill = 0)     %&gt;% 
    mutate(sentiment = positive - negative) 
  
  playDF = tibble(Play = play,Sentiments = names(sentiments),Values = t(sentiments)[,1])
  df = rbind(df,playDF)
}</code></pre>
</div>
